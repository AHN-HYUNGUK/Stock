import datetime, os, re, requests
from collections import Counter
from bs4 import BeautifulSoup
from googletrans import Translator


# âœ… í™˜ê²½ ë³€ìˆ˜
TOKEN = os.environ['TOKEN']
CHAT_ID = os.environ['CHAT_ID']
NEWS_API_KEY = os.environ['NEWSAPI']
EXCHANGE_KEY = os.environ['EXCHANGEAPI']
TWELVE_API_KEY = os.environ["TWELVEDATA_API"]
TELEGRAM_URL = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
today = datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')

translator = Translator()


# âœ… ë¯¸êµ­ ì§€ìˆ˜ í¬ë¡¤ë§ (Investing.com)
def get_us_indices():
    url = "https://www.investing.com/indices/major-indices"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    rows = soup.select("table tbody tr")[:3]
    results = []
    for row in rows:
        try:
            name = row.select_one("td:nth-child(2)").text.strip()
            now = float(
                row.select_one("td:nth-child(3)").text.strip().replace(
                    ",", ""))
            prev = float(
                row.select_one("td:nth-child(4)").text.strip().replace(
                    ",", ""))
            diff = now - prev
            rate = (diff / prev) * 100
            icon = "â–²" if diff > 0 else "â–¼" if diff < 0 else "-"
            results.append(
                f"{name}: {now:,.2f} {icon}{abs(diff):,.2f} ({rate:+.2f}%)")
        except:
            results.append(f"{name}: ë°ì´í„° ì˜¤ë¥˜")
    return "\n".join(results)


# âœ… í™˜ìœ¨
def get_exchange_rates():
    url = f"https://v6.exchangerate-api.com/v6/{EXCHANGE_KEY}/latest/USD"
    res = requests.get(url).json()
    try:
        rates = res["conversion_rates"]
        return (f"USD: 1.00 ê¸°ì¤€\n"
                f"KRW: {rates['KRW']:.2f}\n"
                f"JPY (100ì—”): {rates['JPY'] * 100:.2f}\n"
                f"EUR: {rates['EUR']:.2f}\n"
                f"CNY: {rates['CNY']:.2f}")
    except:
        return "(í™˜ìœ¨ ì •ë³´ ì—†ìŒ)"


# âœ… ì„¹í„°ë³„ ETF
def get_sector_etf_changes(api_key):
    etfs = {
        "ðŸ’» ê¸°ìˆ ": "XLK",
        "ðŸ¦ ê¸ˆìœµ": "XLF",
        "ðŸ’Š í—¬ìŠ¤ì¼€ì–´": "XLV",
        "âš¡ ì—ë„ˆì§€": "XLE",
        "ðŸ›’ ì†Œë¹„ìž¬": "XLY"
    }
    result = []
    for name, symbol in etfs.items():
        url = f"https://api.twelvedata.com/quote?symbol={symbol}&apikey={api_key}"
        try:
            res = requests.get(url).json()
            price = float(res["close"])
            change = float(res["change"])
            percent = float(res["percent_change"])
            icon = "â–²" if change > 0 else "â–¼" if change < 0 else "-"
            result.append(
                f"{name}: {price:.2f} {icon}{abs(change):.2f} ({percent:+.2f}%)"
            )
        except:
            result.append(f"{name}: ì •ë³´ ì—†ìŒ")
    return "\n".join(result)



# âœ… ë„¤ì´ë²„ í•œêµ­ë‰´ìŠ¤ í¬ë¡¤ë§
def fetch_naver_sector_news(sector_dict):
    headers = {"User-Agent": "Mozilla/5.0"}
    message = ""
    for sector, keywords in sector_dict.items():
        news_items = []
        for kw in keywords:
            url = f"https://search.naver.com/search.naver?where=news&query={kw}"
            try:
                res = requests.get(url, headers=headers, timeout=5)
                soup = BeautifulSoup(res.text, "html.parser")
                articles = soup.select("ul.list_news div.news_area a.tit")[:2]
                for a in articles:
                    title = a.text.strip()
                    link = a['href']
                    news_items.append(f"â€¢ {title}\nðŸ‘‰ {link}")
            except:
                continue
        if news_items:
            message += f"{sector}\n" + "\n".join(news_items[:2]) + "\n\n"
    return message or "(ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ)\n"

# âœ… ë„¤ì´ë²„ ë¯¸êµ­ë‰´ìŠ¤ í¬ë¡¤ë§
def fetch_us_world_news():
    url = "https://search.naver.com/search.naver?where=news&query=ë¯¸êµ­ ì¦ì‹œ OR ë¯¸êµ­ ê²½ì œ"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        items = soup.select("ul.list_news div.news_area a.tit")[:3]
        return "\n".join(f"â€¢ {a.text.strip()}\nðŸ‘‰ {a['href']}" for a in items)
    except:
        return "(ë¯¸êµ­ ê´€ë ¨ ì„¸ê³„ ë‰´ìŠ¤ ì—†ìŒ)"



# âœ… ë©”ì‹œì§€ ìž‘ì„± ë° ì „ì†¡
message = f"ðŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œìž¥ ì§€í‘œ\n\n"
message += f"ðŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
message += f"ðŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
message += f"ðŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVE_API_KEY)}\n\n"
message += f"ðŸ‡°ðŸ‡· í•œêµ­ ì¦ì‹œ ë‰´ìŠ¤ (ì—…ì¢…ë³„):\n{fetch_naver_sector_news(sector_keywords_kr)}"
message += f"ðŸŒŽ ë¯¸êµ­ ê´€ë ¨ ì„¸ê³„ ë‰´ìŠ¤:\n{fetch_us_world_news()}\n"


res = requests.post(TELEGRAM_URL, data={"chat_id": CHAT_ID, "text": message})
print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code)
print("ðŸ“¨ ì‘ë‹µ ë‚´ìš©:", res.text)

import schedule
import time


def send_to_telegram():
    # ì—¬ê¸°ì— ê¸°ì¡´ í…”ë ˆê·¸ëž¨ ë©”ì‹œì§€ ìƒì„± + ì „ì†¡ ë¡œì§ì„ í†µì§¸ë¡œ ë„£ìœ¼ë©´ ë¨
    print("ðŸ•– ë‰´ìŠ¤ ì „ì†¡ ì‹œìž‘")
    res = requests.post(TELEGRAM_URL,
                        data={
                            "chat_id": CHAT_ID,
                            "text": message
                        })
    print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code)
    print("ðŸ“¨ ì‘ë‹µ ë‚´ìš©:", res.text)


# âœ… ë§¤ì¼ ì˜¤ì „ 7ì‹œ, ì˜¤í›„ 3ì‹œì— ì‹¤í–‰ë˜ë„ë¡ ì˜ˆì•½
schedule.every().day.at("07:00").do(send_to_telegram)
schedule.every().day.at("15:00").do(send_to_telegram)

# âœ… ê³„ì† ì‹¤í–‰í•˜ë©´ì„œ ì‹œê°„ ì²´í¬
while True:
    schedule.run_pending()
    time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
