import datetime, os, re, requests
from collections import Counter
from bs4 import BeautifulSoup
from googletrans import Translator


# âœ… í™˜ê²½ ë³€ìˆ˜
TOKEN = os.environ['TOKEN']
CHAT_ID = os.environ['CHAT_ID']
NEWS_API_KEY = os.environ['NEWSAPI']
EXCHANGE_KEY = os.environ['EXCHANGEAPI']
TWELVE_API_KEY = os.environ["TWELVEDATA_API"]
TELEGRAM_URL = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
today = datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')

translator = Translator()


# âœ… ë¯¸êµ­ ì§€ìˆ˜ í¬ë¡¤ë§ (Investing.com)
def get_us_indices():
    url = "https://www.investing.com/indices/major-indices"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    rows = soup.select("table tbody tr")[:3]
    results = []
    for row in rows:
        try:
            name = row.select_one("td:nth-child(2)").text.strip()
            now = float(
                row.select_one("td:nth-child(3)").text.strip().replace(
                    ",", ""))
            prev = float(
                row.select_one("td:nth-child(4)").text.strip().replace(
                    ",", ""))
            diff = now - prev
            rate = (diff / prev) * 100
            icon = "â–²" if diff > 0 else "â–¼" if diff < 0 else "-"
            results.append(
                f"{name}: {now:,.2f} {icon}{abs(diff):,.2f} ({rate:+.2f}%)")
        except:
            results.append(f"{name}: ë°ì´í„° ì˜¤ë¥˜")
    return "\n".join(results)


# âœ… í™˜ìœ¨
def get_exchange_rates():
    url = f"https://v6.exchangerate-api.com/v6/{EXCHANGE_KEY}/latest/USD"
    res = requests.get(url).json()
    try:
        rates = res["conversion_rates"]
        return (f"USD: 1.00 ê¸°ì¤€\n"
                f"JPY (100ì—”): {rates['JPY'] * 100:.2f}\n"
                f"EUR: {rates['EUR']:.2f}\n"
                f"CNY: {rates['CNY']:.2f}")
    except:
        return "(í™˜ìœ¨ ì •ë³´ ì—†ìŒ)"


# âœ… ì„¹í„°ë³„ ETF
def get_sector_etf_changes(api_key):
    etfs = {
        "ðŸ’» ê¸°ìˆ ": "XLK",
        "ðŸ¦ ê¸ˆìœµ": "XLF",
        "ðŸ’Š í—¬ìŠ¤ì¼€ì–´": "XLV",
        "âš¡ ì—ë„ˆì§€": "XLE",
        "ðŸ›’ ì†Œë¹„ìž¬": "XLY"
    }
    result = []
    for name, symbol in etfs.items():
        url = f"https://api.twelvedata.com/quote?symbol={symbol}&apikey={api_key}"
        try:
            res = requests.get(url).json()
            price = float(res["close"])
            change = float(res["change"])
            percent = float(res["percent_change"])
            icon = "â–²" if change > 0 else "â–¼" if change < 0 else "-"
            result.append(
                f"{name}: {price:.2f} {icon}{abs(change):.2f} ({percent:+.2f}%)"
            )
        except:
            result.append(f"{name}: ì •ë³´ ì—†ìŒ")
    return "\n".join(result)


# âœ… ê¸°ì‚¬ ìš”ì•½
def get_article_text(url):
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")
        paragraphs = soup.find_all('p')
        text = "\n".join([p.text for p in paragraphs])
        return text.strip()
    except:
        return "(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"


def summarize_text(text, max_sentences=3):
    sentences = re.split(r'(?<=[.?!])\s+', text)
    if len(sentences) <= max_sentences:
        return text
    words = re.findall(r'\w+', text.lower())
    freq = Counter(words)
    ranked = sorted(sentences,
                    key=lambda s: sum(freq[w]
                                      for w in re.findall(r'\w+', s.lower())),
                    reverse=True)
    return " ".join(ranked[:max_sentences])


def get_translated_summary(url):
    text = get_article_text(url)
    if text.startswith("(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"):
        return text
    summary_en = summarize_text(text)
    try:
        return translator.translate(summary_en, src='en', dest='ko').text
    except:
        return "(ë²ˆì—­ ì‹¤íŒ¨)"


# âœ… ë‰´ìŠ¤ ìˆ˜ì§‘
def fetch_news(keyword, lang="en"):
    from_date = (datetime.datetime.now() -
                 datetime.timedelta(days=2)).strftime("%Y-%m-%d")
    to_date = datetime.datetime.now().strftime("%Y-%m-%d")
    url = (f"https://newsapi.org/v2/everything?"
           f"q={keyword}&language={lang}&sortBy=publishedAt&pageSize=5"
           f"&from={from_date}&to={to_date}&apiKey={NEWS_API_KEY}")
    return requests.get(url).json()


def get_filtered_articles(articles):
    return articles[:2]  # í•„í„° ì œê±° (ì‹ ë¢° ì–¸ë¡ ë§Œ ì œí•œí•˜ì§€ ì•ŠìŒ)


# âœ… ì—…ì¢…ë³„ ë‰´ìŠ¤ ë¶„ë¥˜
sector_keywords_en = {
    "ðŸ“ˆ ì‹œìž¥ì „ë°˜": [
        "stock market", "Dow", "Nasdaq", "S&P", "Fed", "inflation",
        "interest rate", "bond yields", "rate hike", "treasury", "US economy",
        "economy news", "market news", "stock news", "JP Morgan", "goldman",
        "wall street", "powell", "yellen"
    ],
    "ðŸ’» ê¸°ìˆ ": [
        "technology", "semiconductor", "AI", "Apple", "Nvidia", "Microsoft",
        "Google", "Tesla", "big tech", "tech stocks", "tech sector",
        "tech news", "tech trends", "IONQ", "Palantir"
    ],
    "ðŸ¦ ê¸ˆìœµ": [
        "finance", "bank", "JP Morgan", "Goldman Sachs", "credit",
        "earnings report", "loan", "insurance", "financial news"
    ],
    "êµ­ì œì´ìŠˆ":
    ["tramp", "china", "iran", "ukraine", "EU", "NATO", "war", "nuclear"]
}

sector_keywords_kr = {
    "ðŸ“ˆ í•œêµ­ì¦ì‹œ": ["ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "í™˜ìœ¨", "ê¸ˆë¦¬", "ë¬´ì—­ìˆ˜ì§€", "ì™¸êµ­ì¸ ë§¤ìˆ˜", "ì™¸í™˜ë³´ìœ ì•¡"],
    "ðŸ’» ITÂ·ë°˜ë„ì²´": ["ì‚¼ì„±ì „ìž", "ë°˜ë„ì²´", "AI", "SKí•˜ì´ë‹‰ìŠ¤", "ì´ì°¨ì „ì§€", "OLED", "DDR5", "AI"],
    "ðŸš— ìžë™ì°¨Â·ëª¨ë¹Œë¦¬í‹°": ["í˜„ëŒ€ì°¨", "ê¸°ì•„", "ì „ê¸°ì°¨", "ìžìœ¨ì£¼í–‰", "ë°°í„°ë¦¬", "UAM", "ì¹œí™˜ê²½ì°¨"],
    "ì •ì¹˜ì´ìŠˆ": ["ì´ìž¬ëª…", "ìœ¤ì„ì—´", "êµ­íšŒ", "íŠ¹ê²€"]
}


def fetch_sector_news(sector_dict, lang="en"):
    message = ""
    for sector, keywords in sector_dict.items():
        articles = []
        for kw in keywords:
            res = fetch_news(kw, lang)
            if res.get("status") == "ok":
                articles += get_filtered_articles(res["articles"])
        unique = {a["title"]: a for a in articles}.values()
        if unique:
            message += f"{sector}\n"
            for a in list(unique)[:1]:
                url = a["url"]
                summary = get_translated_summary(
                    url) if lang == "en" else a["title"]
                message += f"â€¢ {summary}\nðŸ‘‰ {url}\n"
            message += "\n"
    return message or "(ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ)\n"


# âœ… ë„¤ì´ë²„ í•œêµ­ë‰´ìŠ¤ í¬ë¡¤ë§
def fetch_korean_finance_news():
    url = "https://finance.naver.com/news/mainnews.naver"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select(".mainNewsList li a")
    titles = [a.text.strip() for a in items if a.text.strip()]
    return "\n".join(f"â€¢ {t}" for t in titles[:3]) or "(í•œêµ­ ë‰´ìŠ¤ ì—†ìŒ)"


# âœ… ë©”ì‹œì§€ ìž‘ì„± ë° ì „ì†¡
message = f"ðŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œìž¥ ì§€í‘œ\n\n"
message += f"ðŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
message += f"ðŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
message += f"ðŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVE_API_KEY)}\n\n"
message += f"ðŸ‡ºðŸ‡¸ ë¯¸êµ­ ì¦ì‹œ ë‰´ìŠ¤ (ì—…ì¢…ë³„):\n{fetch_sector_news(sector_keywords_en, 'en')}"
message += f"ðŸ‡°ðŸ‡· í•œêµ­ ì¦ì‹œ ë‰´ìŠ¤ (ì—…ì¢…ë³„):\n{fetch_sector_news(sector_keywords_kr, 'ko')}"
message += f"\nðŸ‡°ðŸ‡· í•œêµ­ ì£¼ìš” ë‰´ìŠ¤:\n{fetch_korean_finance_news()}\n"
message += "\nì¶œì²˜: newsapi.org / investing.com / twelvedata.com / exchangerate-api.com"

res = requests.post(TELEGRAM_URL, data={"chat_id": CHAT_ID, "text": message})
print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code)
print("ðŸ“¨ ì‘ë‹µ ë‚´ìš©:", res.text)

import schedule
import time


def send_to_telegram():
    # ì—¬ê¸°ì— ê¸°ì¡´ í…”ë ˆê·¸ëž¨ ë©”ì‹œì§€ ìƒì„± + ì „ì†¡ ë¡œì§ì„ í†µì§¸ë¡œ ë„£ìœ¼ë©´ ë¨
    print("ðŸ•– ë‰´ìŠ¤ ì „ì†¡ ì‹œìž‘")
    res = requests.post(TELEGRAM_URL,
                        data={
                            "chat_id": CHAT_ID,
                            "text": message
                        })
    print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code)
    print("ðŸ“¨ ì‘ë‹µ ë‚´ìš©:", res.text)


# âœ… ë§¤ì¼ ì˜¤ì „ 7ì‹œ, ì˜¤í›„ 3ì‹œì— ì‹¤í–‰ë˜ë„ë¡ ì˜ˆì•½
schedule.every().day.at("07:00").do(send_to_telegram)
schedule.every().day.at("15:00").do(send_to_telegram)

# âœ… ê³„ì† ì‹¤í–‰í•˜ë©´ì„œ ì‹œê°„ ì²´í¬
while True:
    schedule.run_pending()
    time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
