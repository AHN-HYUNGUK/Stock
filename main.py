# main.py

import os                  # â† ì´ê²Œ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨!
import datetime
import re
import requests
import schedule
import time
import openai              # â† os ë‹¤ìŒì— import openai
from collections import Counter
from bs4 import BeautifulSoup
from googletrans import Translator


# í™˜ê²½ ë³€ìˆ˜
TOKEN = os.environ['TOKEN']
CHAT_ID = os.environ['CHAT_ID']
EXCHANGE_KEY = os.environ['EXCHANGEAPI']
TWELVE_API_KEY = os.environ["TWELVEDATA_API"]
TELEGRAM_URL = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
today = datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')

translator = Translator()

# âœ… ë¯¸êµ­ ì§€ìˆ˜ í¬ë¡¤ë§
def get_us_indices():
    url = "https://www.investing.com/indices/major-indices"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    rows = soup.select("table tbody tr")[:3]
    results = []
    for row in rows:
        try:
            name = row.select_one("td:nth-child(2)").text.strip()
            now = float(row.select_one("td:nth-child(3)").text.strip().replace(",", ""))
            prev = float(row.select_one("td:nth-child(4)").text.strip().replace(",", ""))
            diff = now - prev
            rate = (diff / prev) * 100
            icon = "â–²" if diff > 0 else "â–¼" if diff < 0 else "-"
            results.append(f"{name}: {now:,.2f} {icon}{abs(diff):,.2f} ({rate:+.2f}%)")
        except:
            results.append(f"{name}: ë°ì´í„° ì˜¤ë¥˜")
    return "\n".join(results)

# âœ… í™˜ìœ¨ (KRW í¬í•¨)
def get_exchange_rates():
    url = f"https://v6.exchangerate-api.com/v6/{EXCHANGE_KEY}/latest/USD"
    res = requests.get(url).json()
    try:
        rates = res["conversion_rates"]
        return (f"USD: 1.00 ê¸°ì¤€\n"
                f"KRW: {rates['KRW']:.2f}\n"
                f"JPY (100ì—”): {rates['JPY'] * 100:.2f}\n"
                f"EUR: {rates['EUR']:.2f}\n"
                f"CNY: {rates['CNY']:.2f}")
    except:
        return "(í™˜ìœ¨ ì •ë³´ ì—†ìŒ)"

# âœ… ë¯¸êµ­ ETF ì„¹í„°ë³„ ì§€ìˆ˜
def get_sector_etf_changes(api_key):
    etfs = {
        "ğŸ’» ê¸°ìˆ ": "XLK",
        "ğŸ¦ ê¸ˆìœµ": "XLF",
        "ğŸ’Š í—¬ìŠ¤ì¼€ì–´": "XLV",
        "âš¡ ì—ë„ˆì§€": "XLE",
        "ğŸ›’ ì†Œë¹„ì¬": "XLY"
    }
    result = []
    for name, symbol in etfs.items():
        try:
            url = f"https://api.twelvedata.com/quote?symbol={symbol}&apikey={api_key}"
            res = requests.get(url).json()
            price = float(res["close"])
            change = float(res["change"])
            percent = float(res["percent_change"])
            icon = "â–²" if change > 0 else "â–¼" if change < 0 else "-"
            result.append(f"{name}: {price:.2f} {icon}{abs(change):.2f} ({percent:+.2f}%)")
        except:
            result.append(f"{name}: ì •ë³´ ì—†ìŒ")
    return "\n".join(result)

# âœ… ë¯¸êµ­ ì¦ì‹œ ë‰´ìŠ¤ ìˆ˜ì§‘ (Investopedia ê¸°ì¤€)
def fetch_us_market_news_titles():
    try:
        url = "https://finance.yahoo.com/"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        # ì£¼ìš” ë‰´ìŠ¤ ì„¹ì…˜
        articles = soup.select("li.js-stream-content a.js-content-viewer")[:3]
        results = []

        for tag in articles:
            title = tag.get_text(strip=True)
            link = tag.get("href")
            if not link.startswith("http"):
                link = "https://finance.yahoo.com" + link
            results.append(f"â€¢ {title}\nğŸ‘‰ {link}")

        return "\n".join(results) if results else "(ê¸°ì‚¬ ì—†ìŒ)"
    except Exception as e:
        return f"(ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e})"




# âœ… GPT-4o mini ìš”ì•½
# def summarize_news_with_gpt(news_titles):
#     if "â—" in news_titles:
#         return "(ë¯¸êµ­ ë‰´ìŠ¤ ìš”ì•½ ì‹¤íŒ¨)"
#     prompt = f"""ë‹¤ìŒì€ ë¯¸êµ­ ì¦ì‹œ ê´€ë ¨ ê¸°ì‚¬ ì œëª©ë“¤ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°í•œ ì•„ì¹¨ ë‰´ìŠ¤ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n\n{news_titles}"""
#     try:
#         response = openai.ChatCompletion.create(
#             model="gpt-4o",
#             messages=[{"role": "user", "content": prompt}],
#             temperature=0.3,
#             max_tokens=300
#         )
#         return response.choices[0].message.content.strip()
#     except Exception as e:
#         return f"(GPT ìš”ì•½ ì‹¤íŒ¨: {e})"





# âœ… ë„¤ì´ë²„ í•œêµ­ ë‰´ìŠ¤ (ë­í‚¹)
def fetch_naver_top10_news():
    try:
        # ì „ì²´ TOP 10 (ëª¨ë“  ì„¹ì…˜ í•©ì‚°)
        url = "https://news.naver.com/main/ranking/popularDay.naver?rankingType=popular_all"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers)
        res.encoding = "utf-8"
        soup = BeautifulSoup(res.text, "html.parser")

        # ì „ì²´ ì¸ê¸° ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        links = soup.select("div.rankingnews_box ul li a")[:10]
        if not links:
            return "(ë­í‚¹ ë‰´ìŠ¤ ì—†ìŒ)"

        result = "ğŸ“Œ ë„¤ì´ë²„ ë­í‚¹ ë‰´ìŠ¤ TOP 10 (ì „ì²´)\n"
        for a in links:
            title = a.text.strip()
            href = a["href"]
            if not href.startswith("http"):
                href = "https://news.naver.com" + href
            result += f"â€¢ {title}\nğŸ‘‰ {href}\n"

        return result

    except Exception as e:
        return f"(ë­í‚¹ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e})"








# âœ… ì „ì²´ ë©”ì‹œì§€ ì‘ì„±
def build_message():
    message = f"ğŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œì¥ ì§€í‘œ\n\n"
    # âœ… GPT ìš”ì•½ ëŒ€ì‹  ë‰´ìŠ¤ ì œëª©ë§Œ ì¶œë ¥
    headlines = fetch_us_market_news_titles()
    message += f"ğŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
    message += f"ğŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
    message += f"ğŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVE_API_KEY)}\n\n"
    message += f"ğŸ“° ë¯¸êµ­ ì¦ì‹œ ì£¼ìš” ê¸°ì‚¬:\n{headlines}\n\n"
    message += f"ğŸ“° ë„¤ì´ë²„ ë­í‚¹ ë‰´ìŠ¤:\n{fetch_naver_top10_news()}\n"
    return message



# âœ… í…”ë ˆê·¸ë¨ ì „ì†¡ í•¨ìˆ˜ (ì•ˆì •í™” ì ìš© ì™„ë£Œ)
def send_to_telegram():
    # 1ì°¨ ë©”ì‹œì§€: ì§€í‘œ + ë¯¸êµ­ ë‰´ìŠ¤
    part1 = (
        f"ğŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œì¥ ì§€í‘œ\n\n"
        f"ğŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
        f"ğŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
        f"ğŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVE_API_KEY)}\n\n"
        f"ğŸ“° ë¯¸êµ­ ì¦ì‹œ ì£¼ìš” ê¸°ì‚¬:\n{fetch_us_market_news_titles()}\n"
    )

    # 2ì°¨ ë©”ì‹œì§€: ë„¤ì´ë²„ ë‰´ìŠ¤ë§Œ ë”°ë¡œ
    part2 = f"ğŸ“° ë„¤ì´ë²„ ë­í‚¹ ë‰´ìŠ¤:\n{fetch_naver_top10_news()}"

    for msg in [part1, part2]:
        if len(msg) > 4000:
            msg = msg[:3990] + "\n(â€» ì¼ë¶€ ìƒëµë¨)"
        res = requests.post(TELEGRAM_URL, data={
            "chat_id": CHAT_ID,
            "text": msg
        })
        print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code)
        print("ğŸ“¨ ì‘ë‹µ ë‚´ìš©:", res.text)



# âœ… ì˜ˆì•½ ì‹¤í–‰ (Replit ë˜ëŠ” ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
schedule.every().day.at("07:00").do(send_to_telegram)
schedule.every().day.at("15:00").do(send_to_telegram)

# âœ… main.py ëë¶€ë¶„ë§Œ ì´ë ‡ê²Œ
if __name__ == "__main__":
    send_to_telegram()
