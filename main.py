import os
import datetime
import requests
import schedule
import time
from collections import Counter
from bs4 import BeautifulSoup
from googletrans import Translator
from playwright.sync_api import sync_playwright
import openai

load_dotenv = None  # dotenv ë¡œë”©ì´ í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬

# í™˜ê²½ ë³€ìˆ˜
TOKEN           = os.environ['TOKEN']
CHAT_ID         = os.environ['CHAT_ID']
EXCHANGE_KEY    = os.environ['EXCHANGEAPI']
TWELVE_API_KEY  = os.environ["TWELVEDATA_API"]
TELEGRAM_URL    = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
today           = datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')

translator = Translator()


def get_us_indices():
    url = "https://www.investing.com/indices/major-indices"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    rows = soup.select("table tbody tr")[:3]
    out = []
    for r in rows:
        try:
            name = r.select_one("td:nth-child(2)").text.strip()
            now  = float(r.select_one("td:nth-child(3)").text.replace(",", ""))
            prev = float(r.select_one("td:nth-child(4)").text.replace(",", ""))
            diff = now - prev
            pct  = diff / prev * 100
            icon = "â–²" if diff>0 else "â–¼" if diff<0 else "-"
            out.append(f"{name}: {now:,.2f} {icon}{abs(diff):.2f} ({pct:+.2f}%)")
        except:
            out.append(f"{name}: ë°ì´í„° ì˜¤ë¥˜")
    return "\n".join(out)


def get_exchange_rates():
    res = requests.get(f"https://v6.exchangerate-api.com/v6/{EXCHANGE_KEY}/latest/USD").json()
    rates = res.get("conversion_rates", {})
    return (
        f"USD: 1.00 ê¸°ì¤€\n"
        f"KRW: {rates.get('KRW',0):.2f}\n"
        f"JPY (100ì—”): {rates.get('JPY',0)*100:.2f}\n"
        f"EUR: {rates.get('EUR',0):.2f}\n"
        f"CNY: {rates.get('CNY',0):.2f}"
    )


def get_sector_etf_changes(api_key):
    etfs = {"ğŸ’» ê¸°ìˆ ":"XLK","ğŸ¦ ê¸ˆìœµ":"XLF","ğŸ’Š í—¬ìŠ¤ì¼€ì–´":"XLV","âš¡ ì—ë„ˆì§€":"XLE","ğŸ›’ ì†Œë¹„ì¬":"XLY"}
    out = []
    for name,sym in etfs.items():
        try:
            j = requests.get(f"https://api.twelvedata.com/quote?symbol={sym}&apikey={api_key}").json()
            p = float(j["close"]); c= float(j["change"]); pct=float(j["percent_change"])
            icon = "â–²" if c>0 else "â–¼" if c<0 else "-"
            out.append(f"{name}: {p:.2f} {icon}{abs(c):.2f} ({pct:+.2f}%)")
        except:
            out.append(f"{name}: ì •ë³´ ì—†ìŒ")
    return "\n".join(out)


def fetch_us_market_news_titles():
    try:
        url = "https://finance.yahoo.com/"
        soup = BeautifulSoup(requests.get(url,headers={"User-Agent":"Mozilla/5.0"}).text, "html.parser")
        arts = soup.select("li.js-stream-content a.js-content-viewer")[:3]
        return "\n".join(
            f"â€¢ {a.get_text(strip=True)}\nğŸ‘‰ { (a['href'] if a['href'].startswith('http') else 'https://finance.yahoo.com'+a['href']) }"
            for a in arts
        ) or "(ê¸°ì‚¬ ì—†ìŒ)"
    except:
        return "(ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨)"


def fetch_media_press_ranking_playwright(press_id="215", count=10):
    url    = f"https://media.naver.com/press/{press_id}/ranking"
    result = f"ğŸ“Œ ì–¸ë¡ ì‚¬ {press_id} ë­í‚¹ ë‰´ìŠ¤ TOP {count}\n"
    with sync_playwright() as p:
        browser = p.chromium.launch(args=["--no-sandbox"])
        page    = browser.new_page()
        page.goto(url); page.wait_for_load_state("networkidle"); page.wait_for_timeout(2000)
        anchors = page.query_selector_all(f"a[href*='/article/{press_id}/']")[:count]
        for a in anchors:
            img = a.query_selector("img")
            title = img.get_attribute("alt").strip() if img and img.get_attribute("alt") else a.inner_text().split("ì¡°íšŒìˆ˜")[0].strip()
            href  = a.get_attribute("href")
            if not href.startswith("http"):
                href = "https://n.news.naver.com" + href
            result += f"â€¢ {title}\nğŸ‘‰ {href}\n"
        browser.close()
    return result if anchors else f"(press/{press_id} ë­í‚¹ ë‰´ìŠ¤ ì—†ìŒ)"


def get_fear_greed_index():
    try:
        url = "https://feargreedindex.io/"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        value_el = soup.select_one("div.value")
        label_el = soup.select_one("div.status")

        if value_el and label_el:
            value = value_el.text.strip()
            label = label_el.text.strip()
            result = f"ğŸ“Œ ê³µí¬Â·íƒìš• ì§€ìˆ˜: {value}ì  ({label})"
            print("[DEBUG] ê³µí¬Â·íƒìš• ì§€ìˆ˜ â†’", result)  # âœ… ë¡œê·¸ ì¶”ê°€
            return result
        else:
            print("[DEBUG] ê³µí¬Â·íƒìš• ì§€ìˆ˜ ìš”ì†Œ ëª» ì°¾ìŒ")
            return "ğŸ“Œ ê³µí¬Â·íƒìš• ì§€ìˆ˜: ìš”ì†Œ ì—†ìŒ (ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥)"
    except Exception as e:
        print("[ERROR] ê³µí¬Â·íƒìš• ì§€ìˆ˜ ì˜ˆì™¸:", e)
        return f"ğŸ“Œ ê³µí¬Â·íƒìš• ì§€ìˆ˜: ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨"




def build_message():
    return (
        f"ğŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œì¥ ì§€í‘œ\n\n"
        f"ğŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
        f"ğŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
        f"ğŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVE_API_KEY)}\n\n"
        f"{get_fear_greed_index()}\n\n"
        f"ğŸ“° ë¯¸êµ­ ì¦ì‹œ ì£¼ìš” ê¸°ì‚¬:\n{fetch_us_market_news_titles()}"
    )



def send_to_telegram():
    part1 = build_message()
    part2 = fetch_media_press_ranking_playwright("215", 10)

    for msg in [part1, part2]:
        if len(msg) > 4000:
            msg = msg[:3990] + "\n(â€» ì¼ë¶€ ìƒëµë¨)"
        res = requests.post(
            TELEGRAM_URL,
            data={"chat_id": CHAT_ID, "text": msg}
        )
        print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code, "| ğŸ“¨", res.text)



# ë§¤ì¼ 07:00, 15:00 KST ì‹¤í–‰
schedule.every().day.at("07:00").do(send_to_telegram)
schedule.every().day.at("15:00").do(send_to_telegram)

if __name__=="__main__":
    send_to_telegram()
