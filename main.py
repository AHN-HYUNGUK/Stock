# main.py

import os
import datetime
import requests
import schedule
import time
from bs4 import BeautifulSoup
from googletrans import Translator
from playwright.sync_api import sync_playwright
import openai
import csv, io  # â† ë²„í•ì§€ìˆ˜ ê³„ì‚°ìš©(FRED CSV íŒŒì‹±)

# (dotenv ì‚¬ìš© ì•ˆ í•˜ë©´ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”)
load_dotenv = None

# â”€â”€ í™˜ê²½ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN           = os.environ['TOKEN']
CHAT_ID         = os.environ['CHAT_ID']
EXCHANGE_KEY    = os.environ['EXCHANGEAPI']
TWELVEDATA_API  = os.environ["TWELVEDATA_API"]
TELEGRAM_URL    = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
today           = datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')

translator = Translator()

# â”€â”€ ì§€í‘œ/ì‹œì„¸ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_us_indices():
    url = "https://www.investing.com/indices/major-indices"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    rows = soup.select("table tbody tr")[:3]
    out = []
    for r in rows:
        try:
            name = r.select_one("td:nth-child(2)").text.strip()
            now  = float(r.select_one("td:nth-child(3)").text.replace(",", ""))
            prev = float(r.select_one("td:nth-child(4)").text.replace(",", ""))
            diff = now - prev
            pct  = diff / prev * 100
            icon = "â–²" if diff > 0 else "â–¼" if diff < 0 else "-"
            out.append(f"{name}: {now:,.2f} {icon}{abs(diff):,.2f} ({pct:+.2f}%)")
        except:
            out.append(f"{name}: ë°ì´í„° ì˜¤ë¥˜")
    return "\n".join(out)

def get_exchange_rates():
    res = requests.get(f"https://v6.exchangerate-api.com/v6/{EXCHANGE_KEY}/latest/USD").json()
    rates = res.get("conversion_rates", {})
    return (
        f"USD: 1.00 ê¸°ì¤€\n"
        f"KRW: {rates.get('KRW', 0):.2f}\n"
        f"JPY (100ì—”): {rates.get('JPY', 0) * 100:.2f}\n"
        f"EUR: {rates.get('EUR', 0):.2f}\n"
        f"CNY: {rates.get('CNY', 0):.2f}"
    )

def get_sector_etf_changes(api_key):
    etfs = {"ğŸ’» ê¸°ìˆ ": "XLK", "ğŸ¦ ê¸ˆìœµ": "XLF", "ğŸ’Š í—¬ìŠ¤ì¼€ì–´": "XLV", "âš¡ ì—ë„ˆì§€": "XLE", "ğŸ›’ ì†Œë¹„ì¬": "XLY"}
    out = []
    for name, sym in etfs.items():
        try:
            j = requests.get(f"https://api.twelvedata.com/quote?symbol={sym}&apikey={api_key}").json()
            p = float(j["close"])
            c = float(j["change"])
            pct = float(j["percent_change"])
            icon = "â–²" if c > 0 else "â–¼" if c < 0 else "-"
            out.append(f"{name}: {p:.2f} {icon}{abs(c):.2f} ({pct:+.2f}%)")
        except:
            out.append(f"{name}: ì •ë³´ ì—†ìŒ")
    return "\n".join(out)

def get_stock_prices(api_key):
    symbols = {
        "Tesla (TSLA)": "TSLA",
        "Nvidia (NVDA)": "NVDA",
        "Apple (AAPL)": "AAPL",
        "Microsoft (MSFT)": "MSFT",
        "Amazon (AMZN)": "AMZN",
        "Meta (META)": "META",
        "Berkshire Hathaway (BRK.B)": "BRK.B"
    }
    out = []
    for name, sym in symbols.items():
        try:
            j = requests.get(f"https://api.twelvedata.com/quote?symbol={sym}&apikey={api_key}").json()
            p = float(j["close"])
            c = float(j["change"])
            pct = float(j["percent_change"])
            icon = "â–²" if c > 0 else "â–¼" if c < 0 else "-"
            out.append(f"â€¢ {name}: ${p:.2f} {icon}{abs(c):.2f} ({pct:+.2f}%)")
        except:
            out.append(f"â€¢ {name}: ì •ë³´ ì—†ìŒ")
    return "ğŸ“Œ ì£¼ìš” ì¢…ëª© ì‹œì„¸:\n" + "\n".join(out)

def get_korean_stock_price(stock_code, name):
    try:
        url = f"https://finance.naver.com/item/sise.naver?code={stock_code}"
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")
        price = soup.select_one("strong#_nowVal").text.replace(",", "")
        change = soup.select_one("span#_change").text.strip().replace(",", "")
        rate = soup.select_one("span#_rate").text.strip()
        icon = "â–²" if "-" not in change else "â–¼"
        return f"â€¢ {name}: {int(price):,}ì› {icon}{change.replace('-', '')} ({rate})"
    except:
        return f"â€¢ {name}: ì •ë³´ ì—†ìŒ"

def fetch_us_market_news_titles():
    try:
        url = "https://finance.yahoo.com/"
        soup = BeautifulSoup(requests.get(url, headers={"User-Agent": "Mozilla/5.0"}).text, "html.parser")
        arts = soup.select("li.js-stream-content a.js-content-viewer")[:3]
        return "\n".join(
            f"â€¢ {a.get_text(strip=True)}\nğŸ‘‰ {a['href'] if a['href'].startswith('http') else 'https://finance.yahoo.com' + a['href']}"
            for a in arts
        ) or "(ê¸°ì‚¬ ì—†ìŒ)"
    except:
        return "(ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨)"

def fetch_media_press_ranking_playwright(press_id="215", count=10):
    url = f"https://media.naver.com/press/{press_id}/ranking"
    result = f"ğŸ“Œ ì–¸ë¡ ì‚¬ {press_id} ë­í‚¹ ë‰´ìŠ¤ TOP {count}\n"
    anchors = []
    with sync_playwright() as p:
        browser = p.chromium.launch(args=["--no-sandbox"])
        page = browser.new_page()
        page.goto(url)
        page.wait_for_load_state("networkidle")
        page.wait_for_timeout(2000)
        anchors = page.query_selector_all(f"a[href*='/article/{press_id}/']")[:count]
        for a in anchors:
            img = a.query_selector("img")
            title = (
                img.get_attribute("alt").strip()
                if img and img.get_attribute("alt")
                else a.inner_text().strip()
            )
            href = a.get_attribute("href")
            if not href.startswith("http"):
                href = "https://n.news.naver.com" + href
            result += f"â€¢ {title}\nğŸ‘‰ {href}\n"
        browser.close()
    return result if anchors else f"â€¢ í˜„ì¬ ì‹œì ì— í•´ë‹¹ ì–¸ë¡ ì‚¬ì˜ ë­í‚¹ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

def get_fear_greed_index():
    try:
        url = "https://api.alternative.me/fng/?limit=1"
        res = requests.get(url, timeout=10).json()
        data = res["data"][0]
        value = data["value"]
        label = data["value_classification"]
        return f"ğŸ“Œ ê³µí¬Â·íƒìš• ì§€ìˆ˜ (ì½”ì¸ Crypto ê¸°ì¤€): {value}ì  ({label})"
    except Exception as e:
        print("[ERROR] ê³µí¬Â·íƒìš• ì§€ìˆ˜ ì˜ˆì™¸:", e)
        return "ğŸ“Œ ê³µí¬Â·íƒìš• ì§€ìˆ˜: ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨"

# â”€â”€ ë²„í•ì§€ìˆ˜ (ì‹ ê·œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fred_latest_value(series_id: str, tries: int = 3, sleep_base: float = 1.0):
    """
    FRED CSVì—ì„œ í•´ë‹¹ ì‹œë¦¬ì¦ˆì˜ 'ê°€ì¥ ìµœì‹  ìœ íš¨ê°’'ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ìµœì‹  í–‰ì´ '.'(ê²°ì¸¡)ì¸ ê²½ìš°ê°€ ë§ì•„ì„œ ì „ì²´ë¥¼ ì½ê³  ì—­ìˆœìœ¼ë¡œ ì²« ìˆ«ì ì°¾ìŒ
    - ë„¤íŠ¸ì›Œí¬/ì¼ì‹œ ì˜¤ë¥˜ ëŒ€ë¹„ ì¬ì‹œë„
    ë°˜í™˜: (date_str, float_value)
    """
    url = f"https://fred.stlouisfed.org/graph/fredgraph.csv?id={series_id}"
    headers = {"User-Agent": "Mozilla/5.0", "Accept": "text/csv"}
    last_exc = None

    for attempt in range(1, tries + 1):
        try:
            r = requests.get(url, headers=headers, timeout=15)
            r.raise_for_status()
            rows = list(csv.DictReader(io.StringIO(r.text)))
            # ë’¤ì—ì„œë¶€í„° ì˜¬ë¼ê°€ë©° '.' ì•„ë‹Œ ìˆ«ìê°’ì„ ì°¾ëŠ”ë‹¤
            for row in reversed(rows):
                raw = (row.get(series_id) or "").strip()
                if raw and raw != ".":
                    return row.get("DATE"), float(raw)
            # ì „ë¶€ '.' ì´ê±°ë‚˜ ë¹ˆ ê°’ì´ë©´ ì˜ˆì™¸
            raise ValueError(f"No numeric observations for {series_id}")
        except Exception as e:
            last_exc = e
            # ì ì§„ì  ëŒ€ê¸° í›„ ì¬ì‹œë„
            time.sleep(sleep_base * attempt)

    # ë§ˆì§€ë§‰ ì˜ˆì™¸ë¥¼ ì˜¬ë¦¼
    raise last_exc


def get_buffett_indicator():
    """
    ë²„í•ì§€ìˆ˜(ê·¼ì‚¬) â‰ˆ (Wilshire 5000 / ë¯¸êµ­ ëª…ëª© GDP) * 100
    - Wilshire 5000 Full Cap Index: 'WILL5000INDFC' ìš°ì„ , ì‹¤íŒ¨ ì‹œ 'WILL5000IND', 'WILL5000PR' ìˆœìœ¼ë¡œ ëŒ€ì²´
    - GDP: 'GDP' (ì‹­ì–µë‹¬ëŸ¬, ë¶„ê¸° SAAR)
    ì£¼ì˜: ì§€ìˆ˜ì™€ GDP ë‹¨ìœ„ ì°¨ì´ ë•Œë¬¸ì— 'ì ˆëŒ€ ì •í™•'í•˜ì§„ ì•Šì§€ë§Œ ë°©í–¥ì„±/ìˆ˜ì¤€ì€ ì˜ ë°˜ì˜ë©ë‹ˆë‹¤.
    """
    try:
        wilshire_candidates = ["WILL5000INDFC", "WILL5000IND", "WILL5000PR"]
        wil_date = wil_val = None

        # Wilshire ì‹œë¦¬ì¦ˆ ìˆœì°¨ ì‹œë„
        for sid in wilshire_candidates:
            try:
                wil_date, wil_val = fred_latest_value(sid)
                break
            except Exception:
                continue

        if wil_val is None:
            return "ğŸ“ ë²„í•ì§€ìˆ˜: ë°ì´í„° ì—†ìŒ"

        # GDP
        gdp_date, gdp_val = fred_latest_value("GDP")

        ratio = (wil_val / gdp_val) * 100.0

        if ratio < 75:
            label = "ì €í‰ê°€ êµ¬ê°„"
        elif ratio < 90:
            label = "ì•½ê°„ ì €í‰ê°€"
        elif ratio < 115:
            label = "ì ì • ë²”ìœ„"
        elif ratio < 135:
            label = "ì•½ê°„ ê³ í‰ê°€"
        else:
            label = "ê³ í‰ê°€ ê²½ê³ "

        return (
            f"ğŸ“ ë²„í•ì§€ìˆ˜(ê·¼ì‚¬): {ratio:.0f}% â€” {label}\n"
            f"    Â· Wilshire: {wil_val:,.0f} (ê¸°ì¤€ {wil_date})\n"
            f"    Â· GDP: {gdp_val:,.0f} (ê¸°ì¤€ {gdp_date})"
        )
    except Exception as e:
        # ê¹”ë”í•˜ê²Œ í…”ë ˆê·¸ë¨ì—ëŠ” 'ë°ì´í„° ì—†ìŒ'ë§Œ ë³´ë‚´ë˜, ë¡œê·¸ë¡œ ì›ì¸ ë‚¨ê¹€
        print("[WARN] Buffett indicator error:", repr(e))
        return "ğŸ“ ë²„í•ì§€ìˆ˜: ë°ì´í„° ì—†ìŒ"




# â”€â”€ ë©”ì‹œì§€ êµ¬ì„±/ì „ì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_message():
    return (
        f"ğŸ“ˆ [{today}] ë‰´ìŠ¤ ìš”ì•½ + ì‹œì¥ ì§€í‘œ\n\n"
        f"ğŸ“Š ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜:\n{get_us_indices()}\n\n"
        f"ğŸ’± í™˜ìœ¨:\n{get_exchange_rates()}\n\n"
        f"ğŸ“‰ ë¯¸êµ­ ì„¹í„°ë³„ ì§€ìˆ˜ ë³€í™”:\n{get_sector_etf_changes(TWELVEDATA_API)}\n\n"
        f"{get_buffett_indicator()}\n"         # â† ë²„í•ì§€ìˆ˜ ì¶”ê°€
        f"{get_fear_greed_index()}\n\n"
        f"{get_stock_prices(TWELVEDATA_API)}\n\n"
        f"ğŸ“° ì„¸ê³„ ì–¸ë¡ ì‚¬ ë­í‚¹ ë‰´ìŠ¤ (press 074):\n{fetch_media_press_ranking_playwright('074', 3)}"
    )

def send_to_telegram():
    part1 = build_message()
    part2 = fetch_media_press_ranking_playwright("215", 10)

    for msg in [part1, part2]:
        if len(msg) > 4000:
            msg = msg[:3990] + "\n(â€» ì¼ë¶€ ìƒëµë¨)"
        res = requests.post(
            TELEGRAM_URL,
            data={"chat_id": CHAT_ID, "text": msg}
        )
        print("âœ… ì‘ë‹µ ì½”ë“œ:", res.status_code, "| ğŸ“¨", res.text)

# â”€â”€ ìŠ¤ì¼€ì¤„ëŸ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
schedule.every().day.at("07:00").do(send_to_telegram)
schedule.every().day.at("15:00").do(send_to_telegram)

if __name__ == "__main__":
    send_to_telegram()
